{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 23:10:35.215559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743574235.239017  581660 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743574235.246126  581660 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743574235.264156  581660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743574235.264178  581660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743574235.264181  581660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743574235.264183  581660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-01 23:10:35.269850: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from potnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from hf_potnet_model_v3.pt\n",
      "Model loaded from hf_potnet_mid.pt\n"
     ]
    }
   ],
   "source": [
    "high_model = load_model('hf_potnet_model_v3.pt')\n",
    "mid_model = load_model('hf_potnet_mid.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_rows = 271634 - 37247\n",
    "high_rows = 271634 - 15166\n",
    "only_high_data = high_model.generate(high_rows)\n",
    "only_mid_data = mid_model.generate(mid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloads_category\n",
       "High    256468\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_high_data.downloads_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloads_category\n",
       "Mid    234387\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_mid_data.downloads_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1191759 entries, 0 to 1191758\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   model_id             1191759 non-null  object\n",
      " 1   num_downloads        1191759 non-null  int64 \n",
      " 2   num_likes            1191759 non-null  int64 \n",
      " 3   is_private           1191759 non-null  bool  \n",
      " 4   task                 1191759 non-null  object\n",
      " 5   tags                 1191759 non-null  object\n",
      " 6   author               1191759 non-null  object\n",
      " 7   author_category      1191759 non-null  object\n",
      " 8   base_model_relation  322 non-null      object\n",
      " 9   base_model           269144 non-null   object\n",
      " 10  language             1191759 non-null  object\n",
      " 11  model_creator        6528 non-null     object\n",
      " 12  model_type           4578 non-null     object\n",
      " 13  model_name           6433 non-null     object\n",
      " 14  model_card_tags      376770 non-null   object\n",
      " 15  datasets             87053 non-null    object\n",
      " 16  library_name         284851 non-null   object\n",
      " 17  task_group           1191759 non-null  object\n",
      " 18  language_category    1191759 non-null  object\n",
      " 19  downloads_category   1191759 non-null  object\n",
      " 20  base_model_category  269142 non-null   object\n",
      " 21  mixtral_response     269144 non-null   object\n",
      " 22  base_model_params    269142 non-null   object\n",
      " 23  model_type_cleaned   4570 non-null     object\n",
      " 24  location             1191759 non-null  object\n",
      "dtypes: bool(1), int64(2), object(22)\n",
      "memory usage: 219.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/hf_models_withmodelcard_nov2024.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df['tags'] = df['tags'].apply(ast.literal_eval)\n",
    "df['location'] = df['tags'].apply(\n",
    "    lambda tags: next((tag.split(':', 1)[1] for tag in tags if tag.startswith('region:')), None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloads_category\n",
       "Very Low    867712\n",
       "Low         271634\n",
       "Mid          37247\n",
       "High         15166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['task_group', 'author_category', 'language_category', 'downloads_category', 'location']]\n",
    "df.downloads_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloads_category\n",
       "High    256468\n",
       "Mid     234387\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.concat([only_mid_data, only_high_data], ignore_index=True)\n",
    "combined_data.downloads_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloads_category\n",
       "Very Low    867712\n",
       "Low         271634\n",
       "High        271634\n",
       "Mid         271634\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_v2 = pd.concat([df, combined_data], ignore_index=True)\n",
    "combined_data_v2.downloads_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_v2.to_csv('data/generated_data/hf_11_24_generated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows from Very Low (apply stratified sampling, and try to keep equal no. of samples for each task group where downloads category is very low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum count for downloads_category: 271634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449832/929817354.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = combined_data_v2.groupby('downloads_category', group_keys=False).apply(lambda g: stratified_sampling_within_category(g, min_count))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts by downloads_category:\n",
      "downloads_category\n",
      "High        271632\n",
      "Low         271629\n",
      "Mid         271629\n",
      "Very Low    271629\n",
      "Name: count, dtype: int64\n",
      "Within each downloads_category, task_group counts:\n",
      "downloads_category  task_group                    \n",
      "High                Audio Processing                  33954\n",
      "                    Data Analysis & Classification    33954\n",
      "                    Image Processing                  33954\n",
      "                    Multimodal Processing             33954\n",
      "                    Specialized Applications          33954\n",
      "                    Text Processing                   33954\n",
      "                    Unknown                           33954\n",
      "                    Video Processing                  33954\n",
      "Low                 Audio Processing                  30181\n",
      "                    Data Analysis & Classification    30181\n",
      "                    Image Processing                  30181\n",
      "                    Multimodal Processing             30181\n",
      "                    Other                             30181\n",
      "                    Specialized Applications          30181\n",
      "                    Text Processing                   30181\n",
      "                    Unknown                           30181\n",
      "                    Video Processing                  30181\n",
      "Mid                 Audio Processing                  30181\n",
      "                    Data Analysis & Classification    30181\n",
      "                    Image Processing                  30181\n",
      "                    Multimodal Processing             30181\n",
      "                    Other                             30181\n",
      "                    Specialized Applications          30181\n",
      "                    Text Processing                   30181\n",
      "                    Unknown                           30181\n",
      "                    Video Processing                  30181\n",
      "Very Low            Audio Processing                  30181\n",
      "                    Data Analysis & Classification    30181\n",
      "                    Image Processing                  30181\n",
      "                    Multimodal Processing             30181\n",
      "                    Other                             30181\n",
      "                    Specialized Applications          30181\n",
      "                    Text Processing                   30181\n",
      "                    Unknown                           30181\n",
      "                    Video Processing                  30181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Determine the minimum count across downloads_category buckets\n",
    "min_count = combined_data_v2['downloads_category'].value_counts().min()\n",
    "print(\"Minimum count for downloads_category:\", min_count)\n",
    "\n",
    "def stratified_sampling_within_category(group, target):\n",
    "    # Get unique task groups in this downloads_category\n",
    "    unique_tasks = group['task_group'].unique()\n",
    "    n_tasks = len(unique_tasks)\n",
    "    # Determine target sample size per task_group (using integer division)\n",
    "    sample_per_task = target // n_tasks\n",
    "    sampled_frames = []\n",
    "    for task in unique_tasks:\n",
    "        sub_df = group[group['task_group'] == task]\n",
    "        # If sub_df has fewer rows than sample_per_task, sample with replacement; otherwise without\n",
    "        if len(sub_df) < sample_per_task:\n",
    "            sampled = sub_df.sample(n=sample_per_task, replace=True, random_state=42)\n",
    "        else:\n",
    "            sampled = sub_df.sample(n=sample_per_task, random_state=42)\n",
    "        sampled_frames.append(sampled)\n",
    "    # Combine the samples from all task groups within this downloads_category\n",
    "    return pd.concat(sampled_frames)\n",
    "\n",
    "# Apply stratified sampling per downloads_category group\n",
    "sampled_df = combined_data_v2.groupby('downloads_category', group_keys=False).apply(lambda g: stratified_sampling_within_category(g, min_count))\n",
    "\n",
    "print(\"Sample counts by downloads_category:\")\n",
    "print(sampled_df['downloads_category'].value_counts())\n",
    "\n",
    "print(\"Within each downloads_category, task_group counts:\")\n",
    "print(sampled_df.groupby('downloads_category')['task_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no rows where downloads category is high and task_group is 'Other' \n",
    "hence we have low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_group</th>\n",
       "      <th>author_category</th>\n",
       "      <th>language_category</th>\n",
       "      <th>downloads_category</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [task_group, author_category, language_category, downloads_category, location]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.task_group == 'Other') & (df.downloads_category == 'high')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_group</th>\n",
       "      <th>author_category</th>\n",
       "      <th>language_category</th>\n",
       "      <th>downloads_category</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498655</th>\n",
       "      <td>Other</td>\n",
       "      <td>Gold</td>\n",
       "      <td>High</td>\n",
       "      <td>Mid</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595554</th>\n",
       "      <td>Other</td>\n",
       "      <td>Gold</td>\n",
       "      <td>High</td>\n",
       "      <td>Mid</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_group author_category language_category downloads_category  \\\n",
       "498655      Other            Gold              High                Mid   \n",
       "595554      Other            Gold              High                Mid   \n",
       "\n",
       "       location  \n",
       "498655       us  \n",
       "595554       us  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.task_group == 'Other') & (df.downloads_category == 'Mid')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling of Very Low group in Combined Data v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downloads_category\n",
       "Very Low    867712\n",
       "Low         271634\n",
       "High        271634\n",
       "Mid         271634\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/generated_data/hf_11_24_generated.csv')\n",
    "df.downloads_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of task groups in 'Very Low': 9\n",
      "Samples per task group: 30181\n",
      "task_group\n",
      "Text Processing                   30181\n",
      "Unknown                           30181\n",
      "Image Processing                  30181\n",
      "Data Analysis & Classification    30181\n",
      "Audio Processing                  30181\n",
      "Multimodal Processing             30181\n",
      "Specialized Applications          30181\n",
      "Video Processing                  30181\n",
      "Other                             30181\n",
      "Name: count, dtype: int64\n",
      "Total samples in Very Low after sampling: 271629\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows with downloads_category \"Very Low\"\n",
    "very_low_df = df[df['downloads_category'] == 'Very Low']\n",
    "\n",
    "# Get unique task groups in the Very Low category\n",
    "unique_task_groups = very_low_df['task_group'].unique()\n",
    "n_groups = len(unique_task_groups)\n",
    "print(f\"Number of task groups in 'Very Low': {n_groups}\")\n",
    "\n",
    "# Calculate how many samples to take per task group to reach a total of 271,634 samples\n",
    "samples_per_group = 271634 // n_groups\n",
    "print(f\"Samples per task group: {samples_per_group}\")\n",
    "\n",
    "# Perform stratified sampling on each task group\n",
    "sampled_list = []\n",
    "for task in unique_task_groups:\n",
    "    group_df = very_low_df[very_low_df['task_group'] == task]\n",
    "    # If group size is less than required, sample with replacement; otherwise without replacement.\n",
    "    if len(group_df) < samples_per_group:\n",
    "        sampled = group_df.sample(n=samples_per_group, replace=True, random_state=42)\n",
    "    else:\n",
    "        sampled = group_df.sample(n=samples_per_group, random_state=42)\n",
    "    sampled_list.append(sampled)\n",
    "\n",
    "# Concatenate the sampled groups to create a balanced subset\n",
    "very_low_sampled = pd.concat(sampled_list)\n",
    "\n",
    "# Verify the new distribution\n",
    "print(very_low_sampled['task_group'].value_counts())\n",
    "print(\"Total samples in Very Low after sampling:\", len(very_low_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final distribution of downloads_category:\n",
      "downloads_category\n",
      "Low         271634\n",
      "High        271634\n",
      "Mid         271634\n",
      "Very Low    271629\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "not_ver_low_df = df[df['downloads_category'] != 'Very Low']\n",
    "# Concatenate the sampled Very Low data with the rest of the dataset\n",
    "balanced_df = pd.concat([not_ver_low_df, very_low_sampled], ignore_index=True)\n",
    "print(\"Final distribution of downloads_category:\")\n",
    "print(balanced_df['downloads_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.to_csv('data/generated_data/hf_11_24_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
